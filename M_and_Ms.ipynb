{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72e217d-28fd-4c03-ba01-7dd372b7c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b7a3c97-984e-49cd-a7e6-a0acfa91f9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be updated to your root directory also I can send you the images if you want\n",
    "root_dir = '/Users/lucas/Data_Science_Portfolio/M&M project/M&M_images_cropped'\n",
    "\n",
    "validation_dir = os.path.join(root_dir, 'validation')\n",
    "training_dir = os.path.join(root_dir, 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9df6f33-b68c-45d0-952f-991d3d9c9e18",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/Users/lucas/Data_Science_Portfolio/M&M project/M&M_images_cropped/validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(training_dir)\n\u001b[1;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(training_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM&Ms\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda/envs/tensorflow1/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/Users/lucas/Data_Science_Portfolio/M&M project/M&M_images_cropped/validation'"
     ]
    }
   ],
   "source": [
    "# This creates the directories only run this once\n",
    "os.makedirs(validation_dir)\n",
    "os.makedirs(training_dir)\n",
    "\n",
    "os.makedirs(os.path.join(training_dir, 'M&Ms'))\n",
    "os.makedirs(os.path.join(training_dir, 'Not_M&Ms'))\n",
    "\n",
    "os.makedirs(os.path.join(validation_dir, 'M&Ms'))\n",
    "os.makedirs(os.path.join(validation_dir, 'Not_M&Ms'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efd4bda7-4658-4b8c-96f1-5376a9d63dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting stuff up for copying files to the training and validation directories\n",
    "m_and_ms = os.path.join(root_dir, 'M&Ms')\n",
    "\n",
    "split_size = 0.8\n",
    "number_of_m_and_ms = len(os.listdir(m_and_ms))\n",
    "number_of_training = round(number_of_m_and_ms*split_size)\n",
    "m_and_ms_training = os.path.join(training_dir, 'M&Ms')\n",
    "m_and_ms_validation = os.path.join(validation_dir, 'M&Ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53f55ac9-c221-4cea-adb1-8d9ff86279e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the M&M files to the training and validation directories\n",
    "for i in os.listdir(m_and_ms)[:number_of_training]:\n",
    "    if(os.path.getsize(os.path.join(m_and_ms, i))):\n",
    "      copyfile(os.path.join(m_and_ms, i), os.path.join(m_and_ms_training, i))\n",
    "                                 \n",
    "for j in os.listdir(m_and_ms)[number_of_training:]:\n",
    "    if(os.path.getsize(os.path.join(m_and_ms, i))):\n",
    "        copyfile(os.path.join(m_and_ms, j), os.path.join(m_and_ms_validation, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72070c81-2aee-4e2f-b1d4-9873ed81219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the not M&M files to the training and validation directories\n",
    "nots = os.path.join(root_dir, 'Not_M&Ms')\n",
    "\n",
    "not_training = os.path.join(training_dir, 'Not_M&Ms')\n",
    "not_validation = os.path.join(validation_dir, 'Not_M&Ms')\n",
    "number_of_nots = len(os.listdir(nots))\n",
    "number_of_training = round(number_of_nots*split_size)\n",
    "\n",
    "for i in os.listdir(nots)[:number_of_training]:\n",
    "    if(os.path.getsize(os.path.join(nots, i))):\n",
    "        copyfile(os.path.join(nots, i), os.path.join(not_training, i))\n",
    "                       \n",
    "for j in os.listdir(nots)[number_of_training:]:\n",
    "    if(os.path.getsize(os.path.join(nots, j))):\n",
    "        copyfile(os.path.join(nots, j), os.path.join(not_validation, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0556aa56-d998-4b67-a301-d13952bb516c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5162 images belonging to 2 classes.\n",
      "Found 1293 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set up image data generators\n",
    "train_datagen = ImageDataGenerator(rescale= 1/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(directory=training_dir,\n",
    "                                                   batch_size=64,\n",
    "                                                   class_mode='binary',\n",
    "                                                   target_size=(100, 100))\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(directory=validation_dir,\n",
    "                                                              batch_size=64,\n",
    "                                                              class_mode='binary',\n",
    "                                                              target_size=(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34e467bc-d840-4c0e-9452-f6a86bd0cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# define and compile the model\n",
    "\n",
    "model = tf.keras.models.Sequential([ \n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(100, 100, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2), \n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(), \n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'), \n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "  ])\n",
    "    \n",
    "    \n",
    "model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ac1bb9e-a68f-48ee-92f4-eb42a39be6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 11:34:59.634137: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - ETA: 0s - loss: 0.2342 - accuracy: 0.9628"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 11:35:11.131227: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 13s 143ms/step - loss: 0.2342 - accuracy: 0.9628 - val_loss: 0.1156 - val_accuracy: 0.9652\n",
      "Epoch 2/3\n",
      "81/81 [==============================] - 12s 142ms/step - loss: 0.1083 - accuracy: 0.9686 - val_loss: 0.0946 - val_accuracy: 0.9753\n",
      "Epoch 3/3\n",
      "81/81 [==============================] - 12s 142ms/step - loss: 0.0934 - accuracy: 0.9740 - val_loss: 0.0711 - val_accuracy: 0.9807\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history = model.fit(train_generator, \n",
    "                    epochs=3, \n",
    "                    verbose=1, \n",
    "                    validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b4ca3c4-c672-4f5a-85ee-251dc3d8b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to m-and-m.h5\n",
    "model.save(\"m-and-m.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04dfef0-6d8c-4121-842c-5d1d7557c42e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
